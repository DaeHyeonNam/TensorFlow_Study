{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "반복: 1, 손실함수: 0.22321924567222595\n",
      "반복: 2, 손실함수: 0.16759510338306427\n",
      "반복: 3, 손실함수: 0.1442367434501648\n",
      "반복: 4, 손실함수: 0.1341223567724228\n",
      "반복: 5, 손실함수: 0.12098102271556854\n",
      "반복: 6, 손실함수: 0.1147533431649208\n",
      "반복: 7, 손실함수: 0.10860934853553772\n",
      "반복: 8, 손실함수: 0.10383854061365128\n",
      "반복: 9, 손실함수: 0.09903304278850555\n",
      "반복: 10, 손실함수: 0.09233719110488892\n",
      "반복: 11, 손실함수: 0.09402557462453842\n",
      "반복: 12, 손실함수: 0.08987582474946976\n",
      "반복: 13, 손실함수: 0.08966292440891266\n",
      "반복: 14, 손실함수: 0.08673716336488724\n",
      "반복: 15, 손실함수: 0.08461609482765198\n",
      "반복: 16, 손실함수: 0.08402477204799652\n",
      "반복: 17, 손실함수: 0.08344720304012299\n",
      "반복: 18, 손실함수: 0.08146122843027115\n",
      "반복: 19, 손실함수: 0.07931762933731079\n",
      "반복: 20, 손실함수: 0.08148158341646194\n",
      "반복: 21, 손실함수: 0.08045832067728043\n",
      "반복: 22, 손실함수: 0.0790647566318512\n",
      "반복: 23, 손실함수: 0.07771112769842148\n",
      "반복: 24, 손실함수: 0.07771184295415878\n",
      "반복: 25, 손실함수: 0.07749319821596146\n",
      "반복: 26, 손실함수: 0.07568288594484329\n",
      "반복: 27, 손실함수: 0.07397925108671188\n",
      "반복: 28, 손실함수: 0.075593963265419\n",
      "반복: 29, 손실함수: 0.07239279896020889\n",
      "반복: 30, 손실함수: 0.07062169164419174\n",
      "반복: 31, 손실함수: 0.07196309417486191\n",
      "반복: 32, 손실함수: 0.07021162658929825\n",
      "반복: 33, 손실함수: 0.06779211759567261\n",
      "반복: 34, 손실함수: 0.06839915364980698\n",
      "반복: 35, 손실함수: 0.06747061014175415\n",
      "반복: 36, 손실함수: 0.06391342729330063\n",
      "반복: 37, 손실함수: 0.06481683254241943\n",
      "반복: 38, 손실함수: 0.06438014656305313\n",
      "반복: 39, 손실함수: 0.060815002769231796\n",
      "반복: 40, 손실함수: 0.06001616641879082\n",
      "반복: 41, 손실함수: 0.06182008981704712\n",
      "반복: 42, 손실함수: 0.0616474449634552\n",
      "반복: 43, 손실함수: 0.05874770134687424\n",
      "반복: 44, 손실함수: 0.059191763401031494\n",
      "반복: 45, 손실함수: 0.06035260856151581\n",
      "반복: 46, 손실함수: 0.05751479044556618\n",
      "반복: 47, 손실함수: 0.05907385051250458\n",
      "반복: 48, 손실함수: 0.05719522386789322\n",
      "반복: 49, 손실함수: 0.05932261049747467\n",
      "반복: 50, 손실함수: 0.057951848953962326\n",
      "반복: 51, 손실함수: 0.05798983946442604\n",
      "반복: 52, 손실함수: 0.05520157888531685\n",
      "반복: 53, 손실함수: 0.0539698489010334\n",
      "반복: 54, 손실함수: 0.053281042724847794\n",
      "반복: 55, 손실함수: 0.05373762547969818\n",
      "반복: 56, 손실함수: 0.05285632982850075\n",
      "반복: 57, 손실함수: 0.05115553364157677\n",
      "반복: 58, 손실함수: 0.05021844431757927\n",
      "반복: 59, 손실함수: 0.05036764591932297\n",
      "반복: 60, 손실함수: 0.0527813695371151\n",
      "반복: 61, 손실함수: 0.04934309050440788\n",
      "반복: 62, 손실함수: 0.04981769993901253\n",
      "반복: 63, 손실함수: 0.04924275353550911\n",
      "반복: 64, 손실함수: 0.04876113310456276\n",
      "반복: 65, 손실함수: 0.052656933665275574\n",
      "반복: 66, 손실함수: 0.04887450486421585\n",
      "반복: 67, 손실함수: 0.05030966177582741\n",
      "반복: 68, 손실함수: 0.05023643374443054\n",
      "반복: 69, 손실함수: 0.04913735389709473\n",
      "반복: 70, 손실함수: 0.05065172538161278\n",
      "반복: 71, 손실함수: 0.048944395035505295\n",
      "반복: 72, 손실함수: 0.047909755259752274\n",
      "반복: 73, 손실함수: 0.04999718442559242\n",
      "반복: 74, 손실함수: 0.047553014010190964\n",
      "반복: 75, 손실함수: 0.04815905541181564\n",
      "반복: 76, 손실함수: 0.048568520694971085\n",
      "반복: 77, 손실함수: 0.0470755435526371\n",
      "반복: 78, 손실함수: 0.04784898832440376\n",
      "반복: 79, 손실함수: 0.045685261487960815\n",
      "반복: 80, 손실함수: 0.04616828262805939\n",
      "반복: 81, 손실함수: 0.047632500529289246\n",
      "반복: 82, 손실함수: 0.04515112563967705\n",
      "반복: 83, 손실함수: 0.04612426832318306\n",
      "반복: 84, 손실함수: 0.04627170041203499\n",
      "반복: 85, 손실함수: 0.04747403413057327\n",
      "반복: 86, 손실함수: 0.0446796678006649\n",
      "반복: 87, 손실함수: 0.04593168944120407\n",
      "반복: 88, 손실함수: 0.046891435980796814\n",
      "반복: 89, 손실함수: 0.045310672372579575\n",
      "반복: 90, 손실함수: 0.044209178537130356\n",
      "반복: 91, 손실함수: 0.04833831638097763\n",
      "반복: 92, 손실함수: 0.04489343985915184\n",
      "반복: 93, 손실함수: 0.04565178602933884\n",
      "반복: 94, 손실함수: 0.043683022260665894\n",
      "반복: 95, 손실함수: 0.04486054927110672\n",
      "반복: 96, 손실함수: 0.0426148995757103\n",
      "반복: 97, 손실함수: 0.042663753032684326\n",
      "반복: 98, 손실함수: 0.04369913786649704\n",
      "반복: 99, 손실함수: 0.04225574806332588\n",
      "반복: 100, 손실함수: 0.04253673553466797\n",
      "반복: 1, 손실함수: 0.5617390871047974\n",
      "반복: 2, 손실함수: 0.2725171148777008\n",
      "반복: 3, 손실함수: 0.43290507793426514\n",
      "반복: 4, 손실함수: 0.2667379677295685\n",
      "반복: 5, 손실함수: 0.33032721281051636\n",
      "반복: 6, 손실함수: 0.35028958320617676\n",
      "반복: 7, 손실함수: 0.27390754222869873\n",
      "반복: 8, 손실함수: 0.25857141613960266\n",
      "반복: 9, 손실함수: 0.19286057353019714\n",
      "반복: 10, 손실함수: 0.2138536274433136\n",
      "반복: 11, 손실함수: 0.19511428475379944\n",
      "반복: 12, 손실함수: 0.2354126274585724\n",
      "반복: 13, 손실함수: 0.17101755738258362\n",
      "반복: 14, 손실함수: 0.25421810150146484\n",
      "반복: 15, 손실함수: 0.12644442915916443\n",
      "반복: 16, 손실함수: 0.21541741490364075\n",
      "반복: 17, 손실함수: 0.22995330393314362\n",
      "반복: 18, 손실함수: 0.15526369214057922\n",
      "반복: 19, 손실함수: 0.10888023674488068\n",
      "반복: 20, 손실함수: 0.1500861495733261\n",
      "반복: 21, 손실함수: 0.15213337540626526\n",
      "반복: 22, 손실함수: 0.1871575117111206\n",
      "반복: 23, 손실함수: 0.1252984255552292\n",
      "반복: 24, 손실함수: 0.1463540643453598\n",
      "반복: 25, 손실함수: 0.10250344127416611\n",
      "반복: 26, 손실함수: 0.10377071797847748\n",
      "반복: 27, 손실함수: 0.12954534590244293\n",
      "반복: 28, 손실함수: 0.11711467802524567\n",
      "반복: 29, 손실함수: 0.14746595919132233\n",
      "반복: 30, 손실함수: 0.15654268860816956\n",
      "반복: 31, 손실함수: 0.11180329322814941\n",
      "반복: 32, 손실함수: 0.13951866328716278\n",
      "반복: 33, 손실함수: 0.09820098429918289\n",
      "반복: 34, 손실함수: 0.11183461546897888\n",
      "반복: 35, 손실함수: 0.1183299794793129\n",
      "반복: 36, 손실함수: 0.13189098238945007\n",
      "반복: 37, 손실함수: 0.08924473077058792\n",
      "반복: 38, 손실함수: 0.11654339730739594\n",
      "반복: 39, 손실함수: 0.07277452200651169\n",
      "반복: 40, 손실함수: 0.07699479907751083\n",
      "반복: 41, 손실함수: 0.08304823189973831\n",
      "반복: 42, 손실함수: 0.08915658295154572\n",
      "반복: 43, 손실함수: 0.0998833104968071\n",
      "반복: 44, 손실함수: 0.09081970900297165\n",
      "반복: 45, 손실함수: 0.13723255693912506\n",
      "반복: 46, 손실함수: 0.05557788163423538\n",
      "반복: 47, 손실함수: 0.13509628176689148\n",
      "반복: 48, 손실함수: 0.08255129307508469\n",
      "반복: 49, 손실함수: 0.08784569054841995\n",
      "반복: 50, 손실함수: 0.09492210298776627\n",
      "반복: 51, 손실함수: 0.06653869152069092\n",
      "반복: 52, 손실함수: 0.056852757930755615\n",
      "반복: 53, 손실함수: 0.08254924416542053\n",
      "반복: 54, 손실함수: 0.0459599643945694\n",
      "반복: 55, 손실함수: 0.06424417346715927\n",
      "반복: 56, 손실함수: 0.03756922855973244\n",
      "반복: 57, 손실함수: 0.059068311005830765\n",
      "반복: 58, 손실함수: 0.06671781092882156\n",
      "반복: 59, 손실함수: 0.05597706511616707\n",
      "반복: 60, 손실함수: 0.039565250277519226\n",
      "반복: 61, 손실함수: 0.09455260634422302\n",
      "반복: 62, 손실함수: 0.04932915419340134\n",
      "반복: 63, 손실함수: 0.06323499232530594\n",
      "반복: 64, 손실함수: 0.058682315051555634\n",
      "반복: 65, 손실함수: 0.054389115422964096\n",
      "반복: 66, 손실함수: 0.06265049427747726\n",
      "반복: 67, 손실함수: 0.04359680041670799\n",
      "반복: 68, 손실함수: 0.035364456474781036\n",
      "반복: 69, 손실함수: 0.05383102223277092\n",
      "반복: 70, 손실함수: 0.033835310488939285\n",
      "반복: 71, 손실함수: 0.05480845272541046\n",
      "반복: 72, 손실함수: 0.06037602573633194\n",
      "반복: 73, 손실함수: 0.0743337944149971\n",
      "반복: 74, 손실함수: 0.04027146100997925\n",
      "반복: 75, 손실함수: 0.05470430105924606\n",
      "반복: 76, 손실함수: 0.0632733404636383\n",
      "반복: 77, 손실함수: 0.02057519555091858\n",
      "반복: 78, 손실함수: 0.06162264198064804\n",
      "반복: 79, 손실함수: 0.030933810397982597\n",
      "반복: 80, 손실함수: 0.0261993370950222\n",
      "반복: 81, 손실함수: 0.028618652373552322\n",
      "반복: 82, 손실함수: 0.056075360625982285\n",
      "반복: 83, 손실함수: 0.027272632345557213\n",
      "반복: 84, 손실함수: 0.05452707037329674\n",
      "반복: 85, 손실함수: 0.029325660318136215\n",
      "반복: 86, 손실함수: 0.026355350390076637\n",
      "반복: 87, 손실함수: 0.0382840633392334\n",
      "반복: 88, 손실함수: 0.03866131231188774\n",
      "반복: 89, 손실함수: 0.04820447042584419\n",
      "반복: 90, 손실함수: 0.06377141177654266\n",
      "반복: 91, 손실함수: 0.05112621933221817\n",
      "반복: 92, 손실함수: 0.04736412316560745\n",
      "반복: 93, 손실함수: 0.017482124269008636\n",
      "반복: 94, 손실함수: 0.03442230820655823\n",
      "반복: 95, 손실함수: 0.016866043210029602\n",
      "반복: 96, 손실함수: 0.034615933895111084\n",
      "반복: 97, 손실함수: 0.019477445632219315\n",
      "반복: 98, 손실함수: 0.02803093008697033\n",
      "반복: 99, 손실함수: 0.023139864206314087\n",
      "반복: 100, 손실함수: 0.02550707384943962\n",
      "반복: 101, 손실함수: 0.043050315231084824\n",
      "반복: 102, 손실함수: 0.02199680171906948\n",
      "반복: 103, 손실함수: 0.017756382003426552\n",
      "반복: 104, 손실함수: 0.02205050177872181\n",
      "반복: 105, 손실함수: 0.025419263169169426\n",
      "반복: 106, 손실함수: 0.026938462629914284\n",
      "반복: 107, 손실함수: 0.06404571980237961\n",
      "반복: 108, 손실함수: 0.023578129708766937\n",
      "반복: 109, 손실함수: 0.026150211691856384\n",
      "반복: 110, 손실함수: 0.02018004283308983\n",
      "반복: 111, 손실함수: 0.026325585320591927\n",
      "반복: 112, 손실함수: 0.012579192407429218\n",
      "반복: 113, 손실함수: 0.03739633038640022\n",
      "반복: 114, 손실함수: 0.02059045061469078\n",
      "반복: 115, 손실함수: 0.01909615471959114\n",
      "반복: 116, 손실함수: 0.026470405980944633\n",
      "반복: 117, 손실함수: 0.020930176600813866\n",
      "반복: 118, 손실함수: 0.01824866235256195\n",
      "반복: 119, 손실함수: 0.026717720553278923\n",
      "반복: 120, 손실함수: 0.03456142172217369\n",
      "반복: 121, 손실함수: 0.010178105905652046\n",
      "반복: 122, 손실함수: 0.027913451194763184\n",
      "반복: 123, 손실함수: 0.013365250080823898\n",
      "반복: 124, 손실함수: 0.01957005262374878\n",
      "반복: 125, 손실함수: 0.01907091774046421\n",
      "반복: 126, 손실함수: 0.023892873898148537\n",
      "반복: 127, 손실함수: 0.010877134278416634\n",
      "반복: 128, 손실함수: 0.0226729866117239\n",
      "반복: 129, 손실함수: 0.01358500774949789\n",
      "반복: 130, 손실함수: 0.019422849640250206\n",
      "반복: 131, 손실함수: 0.01110822893679142\n",
      "반복: 132, 손실함수: 0.02091304585337639\n",
      "반복: 133, 손실함수: 0.017619125545024872\n",
      "반복: 134, 손실함수: 0.013540783897042274\n",
      "반복: 135, 손실함수: 0.0197284035384655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복: 136, 손실함수: 0.0188621636480093\n",
      "반복: 137, 손실함수: 0.013431376777589321\n",
      "반복: 138, 손실함수: 0.010004465468227863\n",
      "반복: 139, 손실함수: 0.044416677206754684\n",
      "반복: 140, 손실함수: 0.013999395072460175\n",
      "반복: 141, 손실함수: 0.0091487355530262\n",
      "반복: 142, 손실함수: 0.011671110056340694\n",
      "반복: 143, 손실함수: 0.01377631351351738\n",
      "반복: 144, 손실함수: 0.01962006464600563\n",
      "반복: 145, 손실함수: 0.011507892049849033\n",
      "반복: 146, 손실함수: 0.008837124332785606\n",
      "반복: 147, 손실함수: 0.016159454360604286\n",
      "반복: 148, 손실함수: 0.013342885300517082\n",
      "반복: 149, 손실함수: 0.019755171611905098\n",
      "반복: 150, 손실함수: 0.010456377640366554\n",
      "반복: 151, 손실함수: 0.012785488739609718\n",
      "반복: 152, 손실함수: 0.011430926620960236\n",
      "반복: 153, 손실함수: 0.01149975135922432\n",
      "반복: 154, 손실함수: 0.013453997671604156\n",
      "반복: 155, 손실함수: 0.010278180241584778\n",
      "반복: 156, 손실함수: 0.007542074657976627\n",
      "반복: 157, 손실함수: 0.0085756191983819\n",
      "반복: 158, 손실함수: 0.009154612198472023\n",
      "반복: 159, 손실함수: 0.009883670136332512\n",
      "반복: 160, 손실함수: 0.009346514008939266\n",
      "반복: 161, 손실함수: 0.01188852358609438\n",
      "반복: 162, 손실함수: 0.011174840852618217\n",
      "반복: 163, 손실함수: 0.012071982026100159\n",
      "반복: 164, 손실함수: 0.01628739759325981\n",
      "반복: 165, 손실함수: 0.009199472144246101\n",
      "반복: 166, 손실함수: 0.007917619310319424\n",
      "반복: 167, 손실함수: 0.011003845371305943\n",
      "반복: 168, 손실함수: 0.00876010861247778\n",
      "반복: 169, 손실함수: 0.005768902599811554\n",
      "반복: 170, 손실함수: 0.015206636860966682\n",
      "반복: 171, 손실함수: 0.024784870445728302\n",
      "반복: 172, 손실함수: 0.009386284276843071\n",
      "반복: 173, 손실함수: 0.00865645706653595\n",
      "반복: 174, 손실함수: 0.012606654316186905\n",
      "반복: 175, 손실함수: 0.010764017701148987\n",
      "반복: 176, 손실함수: 0.01577974483370781\n",
      "반복: 177, 손실함수: 0.007649874314665794\n",
      "반복: 178, 손실함수: 0.009288636967539787\n",
      "반복: 179, 손실함수: 0.009807527996599674\n",
      "반복: 180, 손실함수: 0.007849459536373615\n",
      "반복: 181, 손실함수: 0.01695229485630989\n",
      "반복: 182, 손실함수: 0.007137091364711523\n",
      "반복: 183, 손실함수: 0.01331357005983591\n",
      "반복: 184, 손실함수: 0.013919742777943611\n",
      "반복: 185, 손실함수: 0.006417365279048681\n",
      "반복: 186, 손실함수: 0.03593434765934944\n",
      "반복: 187, 손실함수: 0.006752672139555216\n",
      "반복: 188, 손실함수: 0.008931713178753853\n",
      "반복: 189, 손실함수: 0.014431595802307129\n",
      "반복: 190, 손실함수: 0.008330774493515491\n",
      "반복: 191, 손실함수: 0.00936062727123499\n",
      "반복: 192, 손실함수: 0.019968975335359573\n",
      "반복: 193, 손실함수: 0.011124590411782265\n",
      "반복: 194, 손실함수: 0.006603492423892021\n",
      "반복: 195, 손실함수: 0.008530180901288986\n",
      "반복: 196, 손실함수: 0.005874397233128548\n",
      "반복: 197, 손실함수: 0.03339046612381935\n",
      "반복: 198, 손실함수: 0.005827821791172028\n",
      "반복: 199, 손실함수: 0.009588785469532013\n",
      "반복: 200, 손실함수: 0.006864028051495552\n",
      "accuracy: 0.954600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True )\n",
    "\n",
    "learning_rate= 0.02\n",
    "learning_rate_GradientDescent = 0.5\n",
    "training_epochs= 100\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "examples_to_show =10\n",
    "input_size = 784\n",
    "hidden1_size = 256\n",
    "hidden2_size = 128\n",
    "output_size = 10\n",
    "\n",
    "x= tf.placeholder(tf.float32, shape= [None, input_size])\n",
    "y= tf.placeholder(tf.float32, shape = [None, output_size])\n",
    "\n",
    "def build_autoencoder(x):\n",
    "    #인코딩\n",
    "    W1= tf.Variable(tf.random_normal(shape= [input_size, hidden1_size]))\n",
    "    b1= tf.Variable(tf.random_normal(shape= [hidden1_size]))\n",
    "    H1_output = tf.nn.sigmoid(tf.matmul(x,W1)+ b1)\n",
    "    \n",
    "    W2= tf.Variable(tf.random_normal(shape= [hidden1_size, hidden2_size]))\n",
    "    b2= tf.Variable(tf.random_normal(shape= [hidden2_size]))\n",
    "    H2_output = tf.nn.sigmoid(tf.matmul(H1_output,W2)+ b2)\n",
    "    \n",
    "    #특징들을 압축하고 다시 원본데이터를 만듦 \n",
    "    \n",
    "    #디코딩\n",
    "    W3= tf.Variable(tf.random_normal(shape= [hidden2_size, hidden1_size]))\n",
    "    b3= tf.Variable(tf.random_normal(shape= [hidden1_size]))\n",
    "    H3_output = tf.nn.sigmoid(tf.matmul(H2_output,W3)+ b3)\n",
    "\n",
    "    W4= tf.Variable(tf.random_normal(shape= [hidden1_size, input_size]))\n",
    "    b4= tf.Variable(tf.random_normal(shape= [input_size]))\n",
    "    reconstructed_x = tf.nn.sigmoid(tf.matmul(H3_output,W4)+ b4)\n",
    "    \n",
    "    return reconstructed_x, H2_output\n",
    "\n",
    "def fine_tuning_softmax(x):\n",
    "    W_softmax = tf.Variable(tf.random_normal(shape= [hidden2_size, output_size]))\n",
    "    b_softmax = tf.Variable(tf.random_normal(shape= [output_size]))\n",
    "    model= tf.nn.softmax(tf.matmul(x,W_softmax)+ b_softmax)\n",
    "    \n",
    "    return model\n",
    "\n",
    "y_pred, summarized_feature = build_autoencoder(x)\n",
    "y_true = x\n",
    "\n",
    "fine_pred = fine_tuning_softmax(summarized_feature)\n",
    "#preprocessing\n",
    "\n",
    "loss= tf.reduce_mean(tf.pow(y_true- y_pred, 2))\n",
    "optimizer= tf.train.RMSPropOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "#findtuning\n",
    "fine_pred = fine_tuning_softmax(summarized_feature)\n",
    "fine_loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(fine_pred), reduction_indices=[1])) \n",
    "finetuning_train_step = tf.train.GradientDescentOptimizer(learning_rate_GradientDescent).minimize(fine_loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch = int(mnist.train.num_examples/ batch_size)\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _,current_loss = sess.run([train_step, loss], feed_dict = {x: batch_xs})\n",
    "        \n",
    "        if epoch%display_step ==0:\n",
    "            print(\"반복: {}, 손실함수: {}\".format(epoch+1, current_loss))\n",
    "    \n",
    "    for epoch in range(training_epochs+100):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, current_loss= sess.run([finetuning_train_step, fine_loss], feed_dict = {x:batch_xs, y: batch_ys})\n",
    "    \n",
    "        if epoch%display_step ==0:\n",
    "            print(\"반복: {}, 손실함수: {}\".format(epoch+1, current_loss))\n",
    "    \n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(fine_pred, 1), tf.argmax(y,1))\n",
    "    accuracy =tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"accuracy: %f\" %(accuracy.eval(feed_dict={x:mnist.test.images , y: mnist.test.labels})))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow]",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
